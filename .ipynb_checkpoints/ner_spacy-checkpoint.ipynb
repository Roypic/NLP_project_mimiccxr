{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28832b-7f45-4c19-bd70-d90338900774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â∑≤Âä†ËΩΩ spaCy ÈªòËÆ§ NER Ê®°ÂûãÔºöen_core_web_sm\n",
      "\n",
      "===== Á§∫‰æãËæìÂá∫ÔºàÂâç 5 Êù°Ôºâ===== \n",
      "\n",
      "Sentence 1:\n",
      "Text: The lungs are otherwise clear with no evidence of focal opacities concerning for infectious process.\n",
      "spaCy NER: []\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence 2:\n",
      "Text: Right PICC line again extends to the cavoatrial junction.\n",
      "spaCy NER: []\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence 3:\n",
      "Text: Streaky opacity at the left lung base thought likely atelectatic in etiology.\n",
      "spaCy NER: [('Streaky', 0, 7, 'PERSON')]\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence 4:\n",
      "Text: No effusion or pneumothorax.\n",
      "spaCy NER: []\n",
      "--------------------------------------------------------------------------------\n",
      "Sentence 5:\n",
      "Text: There is mild obscuration of the right cardiac border, however, no definite densities are appreciated on the lateral view.\n",
      "spaCy NER: []\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ÂÖ®ÈÉ®Êé®ÁêÜÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞Ôºöspacy_standard_predictions.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\" NER model loadedÔºöen_core_web_sm\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2. read json\n",
    "# --------------------------\n",
    "json_path = \"./sentence_chunk_combined_Annotated.json\"\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations = data[\"annotations\"]  # list of [text, ann]\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3. NER\n",
    "# --------------------------\n",
    "def run_spacy_inference():\n",
    "    results = []\n",
    "\n",
    "    for item in annotations:\n",
    "        text = item[0]\n",
    "\n",
    "        doc = nlp(text)\n",
    "        ents = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"spacy_entities\": ents\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4. excute and print\n",
    "# --------------------------\n",
    "output = run_spacy_inference()\n",
    "\n",
    "print(\"\\n===== showcaseÔºàtop 5Ôºâ===== \\n\")\n",
    "\n",
    "for i, item in enumerate(output[:5]):\n",
    "    print(f\"Sentence {i+1}:\")\n",
    "    print(\"Text:\", item[\"text\"])\n",
    "    print(\"spaCy NER:\", item[\"spacy_entities\"])\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 5. ‰øùÂ≠òÂÆåÊï¥ËæìÂá∫Âà∞Êñá‰ª∂\n",
    "# --------------------------\n",
    "import json\n",
    "with open(\"spacy_standard_predictions.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\nÂÖ®ÈÉ®Êé®ÁêÜÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞Ôºöspacy_standard_predictions.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0396e4b0-5cb7-4b93-bea8-c2955d6fc5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊÄªÊ†∑Êú¨Êï∞Èáè: 100\n",
      "ËÆ≠ÁªÉÈõÜ 70 Êù°ÔºåËØÑ‰º∞ÈõÜ 30 Êù°\n",
      "Âä†ÂÖ•ÂÆû‰ΩìÊ†áÁ≠æ: {'LOCATION', 'ANATOMY', 'FINDING', 'DESCRIPTION', 'OTHER'}\n",
      "‰øùÂ≠òÊàêÂäü: train.spacy\n",
      "‰øùÂ≠òÊàêÂäü: eval.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"No free air below the right hemidiaphragm.\" with entities \"[[12, 17, 'OTHER'], [22, 27, 'LOCATION'], [28, 41,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"2. Enlarged pulmonary arteries are suspicious for ...\" with entities \"[[35, 45, 'DESCRIPTION'], [50, 72, 'FINDING'], [31...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"In comparison with the study of ___, there again a...\" with entities \"[[0, 2, 'OTHER'], [37, 42, 'OTHER'], [43, 48, 'OTH...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The heart size is normal.\" with entities \"[[4, 9, 'ANATOMY'], [18, 24, 'DESCRIPTION'], [0, 4...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Left hilar prominence may be a normal findings in ...\" with entities \"[[26, 28, 'DESCRIPTION'], [29, 30, 'DESCRIPTION'],...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Compared to the prior radiograph, the right IJ lin...\" with entities \"[[74, 81, 'DESCRIPTION'], [69, 73, 'DESCRIPTION'],...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The apperance of the distal left clavicle is stabl...\" with entities \"[[45, 51, 'DESCRIPTION'], [0, 3, 'OTHER'], [14, 16...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Given the acute fluctuations, findings favor mild ...\" with entities \"[[30, 38, 'FINDING'], [45, 49, 'DESCRIPTION'], [63...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Repeat after treatment to document resolution.\" with entities \"[[34, 45, 'DESCRIPTION'], [0, 6, 'OTHER'], [7, 12,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/storage/homefs/hl24f166/.conda/envs/dl_pytorch/lib/python3.9/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"The cardiac silhouette is mildly enlarged with lef...\" with entities \"[[4, 22, 'ANATOMY'], [47, 51, 'LOCATION'], [0, 3, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20  Losses={'ner': 574.5058591766725}\n",
      "Epoch 2/20  Losses={'ner': 433.9428211705683}\n",
      "Epoch 3/20  Losses={'ner': 354.1707157610513}\n",
      "Epoch 4/20  Losses={'ner': 294.17886770099926}\n",
      "Epoch 5/20  Losses={'ner': 243.1009385932815}\n",
      "Epoch 6/20  Losses={'ner': 209.48549465060808}\n",
      "Epoch 7/20  Losses={'ner': 163.8420644680413}\n",
      "Epoch 8/20  Losses={'ner': 134.68289650506037}\n",
      "Epoch 9/20  Losses={'ner': 116.5384987037183}\n",
      "Epoch 10/20  Losses={'ner': 85.66910204238084}\n",
      "Epoch 11/20  Losses={'ner': 81.58852478229201}\n",
      "Epoch 12/20  Losses={'ner': 86.85293162214982}\n",
      "Epoch 13/20  Losses={'ner': 81.26762350269799}\n",
      "Epoch 14/20  Losses={'ner': 64.63349874290319}\n",
      "Epoch 15/20  Losses={'ner': 60.12567428249123}\n",
      "Epoch 16/20  Losses={'ner': 67.11685614945976}\n",
      "Epoch 17/20  Losses={'ner': 54.352081922513385}\n",
      "Epoch 18/20  Losses={'ner': 50.40005956448662}\n",
      "Epoch 19/20  Losses={'ner': 54.16552961731887}\n",
      "Epoch 20/20  Losses={'ner': 42.93299904168329}\n",
      "\n",
      "Ê®°ÂûãÂ∑≤‰øùÂ≠òÂà∞ ner_model/\n",
      "\n",
      "===== Evaluation Results =====\n",
      "LOCATION      P=0.0000  R=0.0000  F1=0.0000\n",
      "ANATOMY       P=0.2083  R=0.2381  F1=0.2222\n",
      "FINDING       P=0.4130  R=0.4634  F1=0.4368\n",
      "DESCRIPTION   P=0.2632  R=0.3448  F1=0.2985\n",
      "OTHER         P=0.2683  R=0.3056  F1=0.2857\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.example import Example\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------\n",
    "# 1. Âä†ËΩΩ JSON Êñá‰ª∂\n",
    "# --------------------------\n",
    "json_path = \"./sentence_chunk_combined_Annotated.json\"\n",
    "\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations = data[\"annotations\"]  # list of [text, {\"entities\":[...] }]\n",
    "print(\"ÊÄªÊ†∑Êú¨Êï∞Èáè:\", len(annotations))\n",
    "\n",
    "# --------------------------\n",
    "# 2. Êï∞ÊçÆÈõÜÂàíÂàÜÔºö70% ËÆ≠ÁªÉ / 30% ËØÑ‰º∞\n",
    "# --------------------------\n",
    "train_data, eval_data = train_test_split(\n",
    "    annotations, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ËÆ≠ÁªÉÈõÜ {len(train_data)} Êù°ÔºåËØÑ‰º∞ÈõÜ {len(eval_data)} Êù°\")\n",
    "\n",
    "# --------------------------\n",
    "# 3. ÊûÑÂª∫ spaCy NER Ê†áÁ≠æ‰ΩìÁ≥ª\n",
    "# --------------------------\n",
    "nlp = spacy.blank(\"en\")   # ‰ΩøÁî®Á©∫Ê®°Âûã\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Êî∂ÈõÜÊâÄÊúâÊ†áÁ≠æ\n",
    "all_labels = set()\n",
    "for text, ann in annotations:\n",
    "    for start, end, label in ann[\"entities\"]:\n",
    "        all_labels.add(label)\n",
    "\n",
    "for label in all_labels:\n",
    "    ner.add_label(label)\n",
    "\n",
    "print(\"Âä†ÂÖ•ÂÆû‰ΩìÊ†áÁ≠æ:\", all_labels)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4. ËΩ¨Êç¢Êï∞ÊçÆ‰∏∫ spaCy DocBin\n",
    "# --------------------------\n",
    "def convert_to_spacy(data, output_path):\n",
    "    db = DocBin()\n",
    "    for text, ann in data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in ann[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)\n",
    "    print(\"‰øùÂ≠òÊàêÂäü:\", output_path)\n",
    "\n",
    "convert_to_spacy(train_data, \"train.spacy\")\n",
    "convert_to_spacy(eval_data, \"eval.spacy\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 5. ËÆ≠ÁªÉ NER Ê®°Âûã\n",
    "# --------------------------\n",
    "optimizer = nlp.initialize()\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    losses = {}\n",
    "    for text, ann in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, {\"entities\": ann[\"entities\"]})\n",
    "        nlp.update([example], sgd=optimizer, losses=losses)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}  Losses={losses}\")\n",
    "\n",
    "# ‰øùÂ≠òÊ®°Âûã\n",
    "nlp.to_disk(\"ner_model\")\n",
    "print(\"\\nÊ®°ÂûãÂ∑≤‰øùÂ≠òÂà∞ ner_model/\")\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 6. Âú® evaluation ÈõÜ‰∏äËøõË°åËØÑ‰º∞\n",
    "# --------------------------\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate(nlp, eval_data):\n",
    "    tp = Counter()\n",
    "    fp = Counter()\n",
    "    fn = Counter()\n",
    "\n",
    "    for text, ann in eval_data:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        gold_ents = {(start, end, label) for start, end, label in ann[\"entities\"]}\n",
    "        pred_ents = {(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents}\n",
    "\n",
    "        for ent in pred_ents:\n",
    "            if ent in gold_ents:\n",
    "                tp[ent[2]] += 1\n",
    "            else:\n",
    "                fp[ent[2]] += 1\n",
    "\n",
    "        for ent in gold_ents:\n",
    "            if ent not in pred_ents:\n",
    "                fn[ent[2]] += 1\n",
    "\n",
    "    print(\"\\n===== Evaluation Results =====\")\n",
    "    for label in all_labels:\n",
    "        p = tp[label] / (tp[label] + fp[label] + 1e-8)\n",
    "        r = tp[label] / (tp[label] + fn[label] + 1e-8)\n",
    "        f1 = 2 * p * r / (p + r + 1e-8)\n",
    "        print(f\"{label:12s}  P={p:.4f}  R={r:.4f}  F1={f1:.4f}\")\n",
    "\n",
    "\n",
    "evaluate(nlp, eval_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05920b25-9322-4778-a227-89920bc3ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â∑≤Âä†ËΩΩÊ®°ÂûãÔºöner_model/\n",
      "Evaluation Ê†∑Êú¨Êï∞: 30\n",
      "\n",
      "========================================\n",
      "TEXT:\n",
      "In comparison with the study of ___, there again are low lung volumes that accentuate the prominence of the transverse diameter of the heart.\n",
      "----------------------------------------\n",
      "GOLD:\n",
      "  In [OTHER] (pos 0-2)\n",
      "  there [OTHER] (pos 37-42)\n",
      "  again [OTHER] (pos 43-48)\n",
      "  lung [ANATOMY] (pos 57-61)\n",
      "  heart [ANATOMY] (pos 135-140)\n",
      "  comparison [OTHER] (pos 3-13)\n",
      "  with [OTHER] (pos 14-18)\n",
      "  the [OTHER] (pos 19-22)\n",
      "  accentuate [DESCRIPTION] (pos 75-85)\n",
      "  prominence [DESCRIPTION] (pos 90-100)\n",
      "  low  [FINDING] (pos 53-57)\n",
      "  volumes [FINDING] (pos 62-69)\n",
      "  study [OTHER] (pos 23-28)\n",
      "   of [OTHER] (pos 28-31)\n",
      "  ___ [OTHER] (pos 32-35)\n",
      "  are [OTHER] (pos 49-52)\n",
      "  that [OTHER] (pos 70-74)\n",
      "  the [OTHER] (pos 86-89)\n",
      "  of [OTHER] (pos 101-103)\n",
      "  of [OTHER] (pos 128-130)\n",
      "  the [OTHER] (pos 131-134)\n",
      "  the  [OTHER] (pos 104-108)\n",
      "  transverse diameter [LOCATION] (pos 108-127)\n",
      "\n",
      "PRED:\n",
      "  In [OTHER] (pos 0-2)\n",
      "  comparison [OTHER] (pos 3-13)\n",
      "  with [OTHER] (pos 14-18)\n",
      "  the [OTHER] (pos 19-22)\n",
      "  study [OTHER] (pos 23-28)\n",
      "  there [OTHER] (pos 37-42)\n",
      "  again [OTHER] (pos 43-48)\n",
      "  are [OTHER] (pos 49-52)\n",
      "  low [DESCRIPTION] (pos 53-56)\n",
      "  lung [ANATOMY] (pos 57-61)\n",
      "  volumes [FINDING] (pos 62-69)\n",
      "  that [OTHER] (pos 70-74)\n",
      "  accentuate [DESCRIPTION] (pos 75-85)\n",
      "  the [OTHER] (pos 86-89)\n",
      "  prominence [DESCRIPTION] (pos 90-100)\n",
      "  of [OTHER] (pos 101-103)\n",
      "  the [OTHER] (pos 104-107)\n",
      "  transverse diameter [LOCATION] (pos 108-127)\n",
      "  of [OTHER] (pos 128-130)\n",
      "  the [OTHER] (pos 131-134)\n",
      "  heart [ANATOMY] (pos 135-140)\n",
      "\n",
      "MATCH SUMMARY:\n",
      "üü© TP = 19 üü¶ FP = 2 üü• FN = 4\n",
      "\u001b[32mTP: In [OTHER]\u001b[0m\n",
      "\u001b[32mTP: comparison [OTHER]\u001b[0m\n",
      "\u001b[32mTP: with [OTHER]\u001b[0m\n",
      "\u001b[32mTP: the [OTHER]\u001b[0m\n",
      "\u001b[32mTP: study [OTHER]\u001b[0m\n",
      "\u001b[32mTP: there [OTHER]\u001b[0m\n",
      "\u001b[32mTP: again [OTHER]\u001b[0m\n",
      "\u001b[32mTP: are [OTHER]\u001b[0m\n",
      "\u001b[32mTP: lung [ANATOMY]\u001b[0m\n",
      "\u001b[32mTP: volumes [FINDING]\u001b[0m\n",
      "\u001b[32mTP: that [OTHER]\u001b[0m\n",
      "\u001b[32mTP: accentuate [DESCRIPTION]\u001b[0m\n",
      "\u001b[32mTP: the [OTHER]\u001b[0m\n",
      "\u001b[32mTP: prominence [DESCRIPTION]\u001b[0m\n",
      "\u001b[32mTP: of [OTHER]\u001b[0m\n",
      "\u001b[32mTP: transverse diameter [LOCATION]\u001b[0m\n",
      "\u001b[32mTP: of [OTHER]\u001b[0m\n",
      "\u001b[32mTP: the [OTHER]\u001b[0m\n",
      "\u001b[32mTP: heart [ANATOMY]\u001b[0m\n",
      "\u001b[34mFP: low [DESCRIPTION]\u001b[0m\n",
      "\u001b[34mFP: the [OTHER]\u001b[0m\n",
      "\u001b[31mFN:  of [OTHER]\u001b[0m\n",
      "\u001b[31mFN: ___ [OTHER]\u001b[0m\n",
      "\u001b[31mFN: low  [FINDING]\u001b[0m\n",
      "\u001b[31mFN: the  [OTHER]\u001b[0m\n",
      "\n",
      "========================================\n",
      "TEXT:\n",
      "In comparison to ___ chest radiograph, the heart size remains normal an the lungs are clear.\n",
      "----------------------------------------\n",
      "GOLD:\n",
      "  In comparison to [DESCRIPTION] (pos 0-16)\n",
      "  ___ [OTHER] (pos 17-20)\n",
      "  chest [ANATOMY] (pos 21-26)\n",
      "  radiograph, the [OTHER] (pos 27-42)\n",
      "  heart [ANATOMY] (pos 43-48)\n",
      "  size remains normal [DESCRIPTION] (pos 49-68)\n",
      "  an the [OTHER] (pos 69-75)\n",
      "  lungs [ANATOMY] (pos 76-81)\n",
      "  are clear [FINDING] (pos 82-91)\n",
      "\n",
      "PRED:\n",
      "  In comparison to [DESCRIPTION] (pos 0-16)\n",
      "  ___ [OTHER] (pos 17-20)\n",
      "  chest [ANATOMY] (pos 21-26)\n",
      "  radiograph, the [OTHER] (pos 27-42)\n",
      "  heart [ANATOMY] (pos 43-48)\n",
      "  size remains normal [DESCRIPTION] (pos 49-68)\n",
      "  an the [OTHER] (pos 69-75)\n",
      "  lungs [ANATOMY] (pos 76-81)\n",
      "  are [OTHER] (pos 82-85)\n",
      "  clear [DESCRIPTION] (pos 86-91)\n",
      "\n",
      "MATCH SUMMARY:\n",
      "üü© TP = 8 üü¶ FP = 2 üü• FN = 1\n",
      "\u001b[32mTP: In comparison to [DESCRIPTION]\u001b[0m\n",
      "\u001b[32mTP: ___ [OTHER]\u001b[0m\n",
      "\u001b[32mTP: chest [ANATOMY]\u001b[0m\n",
      "\u001b[32mTP: radiograph, the [OTHER]\u001b[0m\n",
      "\u001b[32mTP: heart [ANATOMY]\u001b[0m\n",
      "\u001b[32mTP: size remains normal [DESCRIPTION]\u001b[0m\n",
      "\u001b[32mTP: an the [OTHER]\u001b[0m\n",
      "\u001b[32mTP: lungs [ANATOMY]\u001b[0m\n",
      "\u001b[34mFP: are [OTHER]\u001b[0m\n",
      "\u001b[34mFP: clear [DESCRIPTION]\u001b[0m\n",
      "\u001b[31mFN: are clear [FINDING]\u001b[0m\n",
      "\n",
      "========================================\n",
      "TEXT:\n",
      "The cardiac, mediastinal and hilar contours are normal.\n",
      "----------------------------------------\n",
      "GOLD:\n",
      "  The [OTHER] (pos 0-3)\n",
      "  cardiac, mediastinal and hilar contours [LOCATION] (pos 4-43)\n",
      "  are [OTHER] (pos 44-47)\n",
      "  normal [DESCRIPTION] (pos 48-54)\n",
      "  . [OTHER] (pos 54-55)\n",
      "\n",
      "PRED:\n",
      "  The [OTHER] (pos 0-3)\n",
      "  cardiac, mediastinal and hilar contours [LOCATION] (pos 4-43)\n",
      "  are [OTHER] (pos 44-47)\n",
      "  normal [DESCRIPTION] (pos 48-54)\n",
      "  . [OTHER] (pos 54-55)\n",
      "\n",
      "MATCH SUMMARY:\n",
      "üü© TP = 5 üü¶ FP = 0 üü• FN = 0\n",
      "\u001b[32mTP: The [OTHER]\u001b[0m\n",
      "\u001b[32mTP: cardiac, mediastinal and hilar contours [LOCATION]\u001b[0m\n",
      "\u001b[32mTP: are [OTHER]\u001b[0m\n",
      "\u001b[32mTP: normal [DESCRIPTION]\u001b[0m\n",
      "\u001b[32mTP: . [OTHER]\u001b[0m\n",
      "\n",
      "========================================\n",
      "TEXT:\n",
      "No focal consolidation, pleural effusion or pneumothorax is identified.\n",
      "----------------------------------------\n",
      "GOLD:\n",
      "  No [OTHER] (pos 0-2)\n",
      "  focal consolidation [FINDING] (pos 3-22)\n",
      "  , [OTHER] (pos 22-23)\n",
      "  pleural effusion [FINDING] (pos 24-40)\n",
      "  or [OTHER] (pos 41-43)\n",
      "  pneumothorax [FINDING] (pos 44-56)\n",
      "  is identified. [OTHER] (pos 57-71)\n",
      "\n",
      "PRED:\n",
      "  No [OTHER] (pos 0-2)\n",
      "  focal consolidation [FINDING] (pos 3-22)\n",
      "  , [OTHER] (pos 22-23)\n",
      "  pleural effusion [FINDING] (pos 24-40)\n",
      "  or [OTHER] (pos 41-43)\n",
      "  pneumothorax [FINDING] (pos 44-56)\n",
      "  is identified. [OTHER] (pos 57-71)\n",
      "\n",
      "MATCH SUMMARY:\n",
      "üü© TP = 7 üü¶ FP = 0 üü• FN = 0\n",
      "\u001b[32mTP: No [OTHER]\u001b[0m\n",
      "\u001b[32mTP: focal consolidation [FINDING]\u001b[0m\n",
      "\u001b[32mTP: , [OTHER]\u001b[0m\n",
      "\u001b[32mTP: pleural effusion [FINDING]\u001b[0m\n",
      "\u001b[32mTP: or [OTHER]\u001b[0m\n",
      "\u001b[32mTP: pneumothorax [FINDING]\u001b[0m\n",
      "\u001b[32mTP: is identified. [OTHER]\u001b[0m\n",
      "\n",
      "========================================\n",
      "TEXT:\n",
      "No acute cardiopulmonary process.\n",
      "----------------------------------------\n",
      "GOLD:\n",
      "  No [OTHER] (pos 0-2)\n",
      "  acute [DESCRIPTION] (pos 3-8)\n",
      "  cardiopulmonary process [FINDING] (pos 9-32)\n",
      "  . [OTHER] (pos 32-33)\n",
      "\n",
      "PRED:\n",
      "  No [DESCRIPTION] (pos 0-2)\n",
      "  acute [DESCRIPTION] (pos 3-8)\n",
      "  cardiopulmonary [FINDING] (pos 9-24)\n",
      "  process [FINDING] (pos 25-32)\n",
      "\n",
      "MATCH SUMMARY:\n",
      "üü© TP = 1 üü¶ FP = 3 üü• FN = 3\n",
      "\u001b[32mTP: acute [DESCRIPTION]\u001b[0m\n",
      "\u001b[34mFP: No [DESCRIPTION]\u001b[0m\n",
      "\u001b[34mFP: cardiopulmonary [FINDING]\u001b[0m\n",
      "\u001b[34mFP: process [FINDING]\u001b[0m\n",
      "\u001b[31mFN: No [OTHER]\u001b[0m\n",
      "\u001b[31mFN: cardiopulmonary process [FINDING]\u001b[0m\n",
      "\u001b[31mFN: . [OTHER]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import spacy\n",
    "from pathlib import Path\n",
    "from termcolor import colored\n",
    "\n",
    "# --------------------------\n",
    "# 1. Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã\n",
    "# --------------------------\n",
    "nlp = spacy.load(\"ner_model\")\n",
    "print(\"Â∑≤Âä†ËΩΩÊ®°ÂûãÔºöner_model/\")\n",
    "\n",
    "# --------------------------\n",
    "# 2. ËØªÂèñ evaluation Êï∞ÊçÆÈõÜ\n",
    "# --------------------------\n",
    "json_path = \"./sentence_chunk_combined_Annotated.json\"\n",
    "with open(json_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "annotations = data[\"annotations\"]\n",
    "\n",
    "# 70/30 ÂàíÂàÜ‰øùÊåÅ‰∏ÄËá¥\n",
    "random.seed(42)\n",
    "random.shuffle(annotations)\n",
    "split = int(len(annotations) * 0.7)\n",
    "eval_data = annotations[split:]\n",
    "\n",
    "print(\"Evaluation Ê†∑Êú¨Êï∞:\", len(eval_data))\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3. Â∑•ÂÖ∑ÂáΩÊï∞ÔºöÊâìÂç∞ÈáëÊ†á‰∏éÈ¢ÑÊµã\n",
    "# --------------------------\n",
    "def format_span(text, start, end, label, color):\n",
    "    return (\n",
    "        text[:start]\n",
    "        + colored(text[start:end], color)\n",
    "        + text[end:]\n",
    "        + f\" <{label}>\"\n",
    "    )\n",
    "\n",
    "def showcase_one(text, gold_ents, pred_ents):\n",
    "    print(\"\\n========================================\")\n",
    "    print(\"TEXT:\")\n",
    "    print(text)\n",
    "    print(\"----------------------------------------\")\n",
    "\n",
    "    print(\"GOLD:\")\n",
    "    for (s, e, label) in gold_ents:\n",
    "        print(f\"  {text[s:e]} [{label}] (pos {s}-{e})\")\n",
    "\n",
    "    print(\"\\nPRED:\")\n",
    "    for (s, e, label) in pred_ents:\n",
    "        print(f\"  {text[s:e]} [{label}] (pos {s}-{e})\")\n",
    "\n",
    "    # TP, FP, FN\n",
    "    gold_set = set(gold_ents)\n",
    "    pred_set = set(pred_ents)\n",
    "\n",
    "    tp = gold_set & pred_set\n",
    "    fp = pred_set - gold_set\n",
    "    fn = gold_set - pred_set\n",
    "\n",
    "    print(\"\\nMATCH SUMMARY:\")\n",
    "    print(\"üü© TP =\", len(tp), \"üü¶ FP =\", len(fp), \"üü• FN =\", len(fn))\n",
    "\n",
    "\n",
    "    def highlight_all():\n",
    "        chunks = []\n",
    "        for s, e, label in sorted(tp, key=lambda x: x[0]):\n",
    "            print(colored(f\"TP: {text[s:e]} [{label}]\", \"green\"))\n",
    "\n",
    "        for s, e, label in sorted(fp, key=lambda x: x[0]):\n",
    "            print(colored(f\"FP: {text[s:e]} [{label}]\", \"blue\"))\n",
    "\n",
    "        for s, e, label in sorted(fn, key=lambda x: x[0]):\n",
    "            print(colored(f\"FN: {text[s:e]} [{label}]\", \"red\"))\n",
    "\n",
    "    highlight_all()\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4. Showcase \n",
    "# --------------------------\n",
    "N = 5  \n",
    "samples = random.sample(eval_data, N)\n",
    "\n",
    "for text, ann in samples:\n",
    "    gold = [(s, e, label) for s, e, label in ann[\"entities\"]]\n",
    "    doc = nlp(text)\n",
    "    pred = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    showcase_one(text, gold, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689f899-4f9d-4a47-9d75-700d00197737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_pytorch)",
   "language": "python",
   "name": "dl_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
